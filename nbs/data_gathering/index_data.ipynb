{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing Data\n",
    "This notebook indexes a subset of the [Yelp Reviews Dataset](https://business.yelp.com/data/resources/open-dataset/) for RAG in a Qdrant database. \n",
    "This is an **research-only** educational database released by Yelp for the purposes of education. \n",
    "More details about the license and terms of use of the dataset can be found in the [description of the dataset](../../data/Yelp_Dataset_Documentation_and_ToS_copy.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wall\n",
    "import tiktoken\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, UnstructuredHTMLLoader\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv; _ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_ROOT = \"../../data/yelp/Yelp_JSON/\"\n",
    "REVIEWS = os.path.join(DATA_ROOT, \"yelp_academic_dataset_review.json\")\n",
    "BUSINESS = os.path.join(DATA_ROOT, \"yelp_academic_dataset_business.json\")\n",
    "CHECKIN = os.path.join(DATA_ROOT, \"yelp_academic_dataset_checkin.json\")\n",
    "TIP = os.path.join(DATA_ROOT, \"yelp_academic_dataset_tip.json\")\n",
    "USER = os.path.join(DATA_ROOT, \"yelp_academic_dataset_user.json\")\n",
    "DATA_SUBSET = os.path.join(DATA_ROOT, \"review_text.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=DATA_SUBSET,\n",
    "    jq_schema='.full_review',\n",
    "    json_lines=True\n",
    ")\n",
    "documents = loader.lazy_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_SIZE = 500_000\n",
    "docs = []\n",
    "for i, doc in enumerate(documents):\n",
    "    if i >= SUBSET_SIZE:\n",
    "        break   \n",
    "    docs.append(doc)\n",
    "del documents\n",
    "documents = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=700,\n",
    "    chunk_overlap=250,\n",
    "    length_function=len\n",
    "  )\n",
    "documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc.metadata['source'] = doc.metadata['source'].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
    "\n",
    "# REPLACE THIS WITH APPROPRIATE DEPLOYMENT URL\n",
    "EMBED_MODEL_URL = \"https://klnki3w1q88gr09t.us-east-1.aws.endpoints.huggingface.cloud\"\n",
    "\n",
    "embeddings = HuggingFaceEndpointEmbeddings(\n",
    "    model=EMBED_MODEL_URL,\n",
    "    task=\"feature-extraction\",\n",
    "    huggingfacehub_api_token=os.environ[\"HF_TOKEN\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\n",
    "    url=os.environ.get('QDRANT_DB_BITTER_MAMMAL'), # Name of the qdrant cluster is bitter_mammal\n",
    "    api_key=os.environ.get('QDRANT_API_KEY_BITTER_MAMMAL'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"yelp_reviews\",\n",
    "    vectors_config=VectorParams(size=1024, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deman/Dev/Maven/MavenAIBootcamp6/AIE6-Certification-Challenge/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"yelp_reviews\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def add_documents(vector_store, documents, start=0):\n",
    "    for i in tqdm(range(start, len(documents), 10)):\n",
    "        batch = documents[i:i+10]\n",
    "        vector_store.add_documents(\n",
    "            documents=batch,\n",
    "        )\n",
    "        with open(\"checkpoint.txt\", \"w\") as f:\n",
    "            f.write(str(start+i+10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83764/83764 [5:19:24<00:00,  4.37it/s]    \n"
     ]
    }
   ],
   "source": [
    "add_documents(vector_store, documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
